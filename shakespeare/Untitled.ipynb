{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a2aad7d-3641-4ce6-b4b2-19301ac4fd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.1+cu121', '1.26.2')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "torch.__version__, np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909f0b7c-cd85-4b70-8944-c2c95a6b28a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATS\n",
      "vocab size:  65\n"
     ]
    }
   ],
   "source": [
    "# !wget \n",
    "import os\n",
    "def fetch_dataset():\n",
    "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "    local_file = os.path.join(os.getcwd(), url.split('/')[-1])\n",
    "    vocab = lambda text: \"\".join(sorted(list(set(text))))\n",
    "    if os.path.exists(local_file):\n",
    "        with open(local_file, 'r') as f:\n",
    "            data = f.read()\n",
    "            return data, len(vocab(data))\n",
    "    else:\n",
    "        response = requests.get(url)\n",
    "        with open(local_file, 'w') as f:\n",
    "            f.write(response.text)\n",
    "        return response.text, len(vocab(data))\n",
    "        \n",
    "dataset, vocab_size = fetch_dataset()\n",
    "# print(\"dataset:\\t\", dataset[:100])\n",
    "print(\"STATS\")\n",
    "print(\"vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f9e2c96-f3e7-4fd1-8279-bbbddfa80378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51, 39, 52, 39, 52]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itoa = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [atoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itoa[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "n1 = int(0.8 * len(dataset))\n",
    "n2 = int(0.9 * len(dataset))\n",
    "block_size = 16\n",
    "\n",
    "encode(\"manan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08df0868-6e93-4c6d-bd0c-6f0b3e56d2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   'F'],\n",
       "  ['\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   'F',\n",
       "   'i'],\n",
       "  ['\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   '\\n',\n",
       "   'F',\n",
       "   'i',\n",
       "   'r']],\n",
       " ['i', 'r', 's'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def markov_split(dset, block_size=32): # using sliding window, a bit too slow,\n",
    "    def sliding_window(dataset):\n",
    "        x = []\n",
    "        y = []\n",
    "        window = [itoa[0]] * block_size\n",
    "        for i in range(len(dataset)-block_size):\n",
    "            X = window[1:] + [dataset[i]]\n",
    "            Y = dataset[i+1]\n",
    "            x.append(X)\n",
    "            y.append(Y)\n",
    "            # res.append((X, Y))\n",
    "            window = X\n",
    "        return x, y\n",
    "\n",
    "    return {\n",
    "        \"train\": sliding_window(dataset[:n1]),\n",
    "        \"val\": sliding_window(dataset[n1:n2]),\n",
    "        \"test\": sliding_window(dataset[n2:]),\n",
    "\n",
    "    }[dset]\n",
    "\n",
    "zip(markov_split(\"train\"))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eddf87ad-f1a5-43ab-9975-6ff319c971f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1, 51, 63,  1, 51, 53, 58, 46, 43, 56,  0, 16, 53, 43, 57,  1, 52, 53,\n",
       "          58,  1, 39, 54, 54, 56, 53, 60, 43,  1, 51, 43,  1, 44],\n",
       "         [ 1, 51, 63, 57, 43, 50, 44,  2,  0, 27,  1, 58, 46, 39, 58,  1, 21,  1,\n",
       "          61, 43, 56, 43,  1, 39,  1, 51, 53, 41, 49, 43, 56, 63],\n",
       "         [46, 53, 50, 63,  1, 28, 39, 59, 50,  6,  1, 58, 46, 43, 63,  1, 50, 53,\n",
       "          60, 43,  1, 46, 47, 57,  1, 45, 56, 39, 41, 43,  1, 40],\n",
       "         [49, 47, 52, 42, 52, 43, 57, 57,  1, 39, 58,  1, 51, 63,  1, 46, 39, 52,\n",
       "          42,  0, 32, 46, 39, 58,  1, 63, 53, 59, 56,  1, 43, 57]]),\n",
       " tensor([[51, 63,  1, 51, 53, 58, 46, 43, 56,  0, 16, 53, 43, 57,  1, 52, 53, 58,\n",
       "           1, 39, 54, 54, 56, 53, 60, 43,  1, 51, 43,  1, 44, 59],\n",
       "         [51, 63, 57, 43, 50, 44,  2,  0, 27,  1, 58, 46, 39, 58,  1, 21,  1, 61,\n",
       "          43, 56, 43,  1, 39,  1, 51, 53, 41, 49, 43, 56, 63,  1],\n",
       "         [53, 50, 63,  1, 28, 39, 59, 50,  6,  1, 58, 46, 43, 63,  1, 50, 53, 60,\n",
       "          43,  1, 46, 47, 57,  1, 45, 56, 39, 41, 43,  1, 40, 59],\n",
       "         [47, 52, 42, 52, 43, 57, 57,  1, 39, 58,  1, 51, 63,  1, 46, 39, 52, 42,\n",
       "           0, 32, 46, 39, 58,  1, 63, 53, 59, 56,  1, 43, 57, 58]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = 4\n",
    "def seq_token_pairs_split(dset, block_size=16): # infinite mini-batches, pair tokenizer\n",
    "    def mini_batches(text):\n",
    "        data = torch.tensor(encode(text), dtype=torch.long)\n",
    "        ix = torch.randint(len(data)-block_size, (batches,))\n",
    "        x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "        y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "        return x, y\n",
    "    return {\n",
    "        \"train\": mini_batches(dataset[:n1]),\n",
    "        \"test\": mini_batches(dataset[n1:n2]),\n",
    "        \"val\": mini_batches(dataset[n2:]),\n",
    "    }[dset]\n",
    "\n",
    "infinite_pair(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e044a6d-7101-463d-8822-eb42a17b2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# basic bigram model\n",
    "\n",
    "W = torch.randn((vocab_size, vocab_size), dtype=torch.float64)\n",
    "W.requires_grad = True\n",
    "# x_enc = C[X]\n",
    "# x_enc[0]\n",
    "epoch = 10000\n",
    "losses = []\n",
    "\n",
    "optimizer = torch.optim.AdamW([W], lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86614a-45ee-49dd-8b72-642bcdcc961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=1/10000 | loss: 4.7188|\n",
      "step=501/10000 | loss: 4.5185|\n",
      "step=1001/10000 | loss: 3.8916|\n",
      "step=1501/10000 | loss: 3.7725|\n",
      "step=2001/10000 | loss: 3.5418|\n"
     ]
    }
   ],
   "source": [
    "for step in range(epoch):\n",
    "    X, Y = create_dset(\"train\")\n",
    " \n",
    "    logits = W[X]\n",
    "    counts = logits.exp() # equivalent N\n",
    "    probs = counts / counts.sum(1, keepdim=True) \n",
    "\n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.view(B*T, C)\n",
    "    Y = Y.view(B*T)\n",
    "    \n",
    "    \n",
    "    loss = F.cross_entropy(logits,Y)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 500 == 1:\n",
    "        print(f\"{step=}/{epoch} | loss: {loss:6.4f}|\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e36a8a-d655-48db-851f-7aba116a0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "losses[-1], W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240ee08-f37a-4a30-9882-7b4d46c9e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_loss(dset):\n",
    "    X, Y = create_dset(dset)\n",
    "    \n",
    "    logits = W[X]\n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.view(B*T, C)\n",
    "    Y = Y.view(B*T)\n",
    "\n",
    "    loss = F.cross_entropy(logits[i],Y[i])    \n",
    "    return loss\n",
    "\n",
    "compute_loss(\"val\"), compute_loss(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27257a04-9768-4605-867a-0d941a809491",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate(dset, idx, max_tokens):\n",
    "    # X, Y = create_dset(dset)\n",
    "\n",
    "\n",
    "    for _ in range(max_tokens):\n",
    "        logits = W[idx]\n",
    "        logits = logits[:, -1, :] \n",
    "\n",
    "        probs = F.softmax(logits, dim=-1)        \n",
    "        idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "        # print(probs.view(-1), idx, idx_next)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "decode(generate(\"test\", torch.zeros((1,1), dtype=torch.int64), 500).numpy()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9946fe-136e-4b4a-8517-2f7d396d5d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.empty((4, 27))\n",
    "b = torch.empty((4, 27))\n",
    "torch.stack((a, b), dim=1).view(4,-1)[:, 0] == torch.cat((a,b), dim=1)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70f329ff-b73e-4592-9a84-870db3507258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.emb = nn.Parameter(nn.Embedding(vocab_size, vocab_size))\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.emb(idx)\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(idx, targets)\n",
    "            return logits, loss\n",
    "        return logits, None\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def generate(max_tokens):\n",
    "        idx = torch.zeros((0,0))\n",
    "        for _ in max_tokens: \n",
    "            logits = self.emb(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.stack((idx, idx_next), dim=1).view(batches,-1)\n",
    "        return decode(idx.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "632a16da-287d-4526-ae8b-4f21207a4637",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBigramModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36mBigramModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parameter.py:42\u001b[0m, in \u001b[0;36mParameter.__new__\u001b[0;34m(cls, data, requires_grad)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39m_make_subclass(\u001b[38;5;28mcls\u001b[39m, data, requires_grad)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Path for custom tensors: set a flag on the instance to indicate parameter-ness.\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\u001b[38;5;241m.\u001b[39mrequires_grad_(requires_grad)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating a Parameter from an instance of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires that detach() returns an instance of the same type, but return \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(t)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was found instead. To use the type as a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter, please correct the detach() semantics defined by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mits __torch_dispatch__() implementation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "epoch = 500\n",
    "model = BigramModel()\n",
    "losses = []\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "for step in range(epoch):\n",
    "    X, Y = create_dset(\"train\")\n",
    "    logits, loss = model(X, Y)        \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "193e83ba-5b04-414e-a47c-f8c734d1ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        n_embd = 1000\n",
    "        self.emb = nn.Embedding(vocab_size, vocab_size)\n",
    "        self.l1 = nn.Linear(vocab_size, n_embd)\n",
    "        self.bn = nn.BatchNorm1d(n_embd, affine=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.l2 = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            self.emb,\n",
    "            self.l1,\n",
    "            self.bn,\n",
    "            self.tanh,\n",
    "            self.l2\n",
    "        )\n",
    "        \n",
    "    def forward(self, idx, targets = None):\n",
    "        embed = self.emb(idx)\n",
    "        track_running_stats=True \n",
    "        momentum = 0.01\n",
    "        idx = self.emb(idx)\n",
    "        print(idx.shape,)\n",
    "        idx = self.l1(idx)\n",
    "        \n",
    "        # logits = self.model(idx)\n",
    "        \n",
    "        \n",
    "        B, C, T = idx.shape\n",
    "        print(idx.shape, vocab_size)\n",
    "        idx = torch.reshape(idx, (B, T, C))\n",
    "        print(idx.shape)\n",
    "        idx = self.bn(idx)\n",
    "        idx = self.tanh(idx)\n",
    "        idx = torch.reshape(idx, (B, T, C))\n",
    "        print(idx.shape)\n",
    "        logits = self.l2(idx)\n",
    "        loss = None\n",
    "\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "        # optim = torch.optim.AdamW(self.model.parameters(), lr=1e-3)\n",
    "        # optim.zero_grad(set_to_none=True)\n",
    "        # loss.backward()\n",
    "        # optim.step()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2f63b3c-dd01-4422-a518-5a2029695df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3842e-10, grad_fn=<MeanBackward0>) tensor(1.0000, grad_fn=<StdBackward0>)\n",
      "torch.Size([4, 32, 65])\n",
      "red\n",
      "With a swain's wearing, and  torch.Size([4, 32]) torch.Size([4, 32, 65]) torch.Size([4, 1, 65])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 500\n",
    "model = MLP()\n",
    "losses = []\n",
    "n_embd = 1000\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "for step in range(epoch):\n",
    "    X, Y = create_dset(\"train\")\n",
    "    B, T = X.shape\n",
    "    C = torch.randn((vocab_size, vocab_size))\n",
    "    r_m = torch.randn((n_embd,))\n",
    "    r_s = torch.randn((n_embd,))\n",
    "    std = torch.zeros((n_embd,))\n",
    "    mean = torch.ones((n_embd,))\n",
    " \n",
    "\n",
    "    # X = torch.reshape(X, (B, C, T))\n",
    "    idx = C[X]\n",
    "    W1 = torch.randn((vocab_size, n_embd))\n",
    "    b1 = torch.randn((n_embd,))\n",
    "    idx = idx @ W1 + b1\n",
    "    B, T, C = idx.shape\n",
    "    v = idx\n",
    "    idx = idx.view(B, T, C)\n",
    "    idx = nn.LayerNorm(n_embd)(idx)\n",
    "    # idx = idx.view(B,T, C)\n",
    "    print(idx[0].mean(), idx[0].std())\n",
    "    plt.hist(idx[0].view(-1).detach().numpy())\n",
    "    idx = torch.tanh(idx)\n",
    "    \n",
    "    plt.hist(idx[0].view(-1).detach().numpy())\n",
    "    W2 = torch.randn((n_embd, vocab_size))\n",
    "    b2 = torch.randn((vocab_size,))\n",
    "    idx = idx @ W2 + b2\n",
    "    print(idx.shape)\n",
    "    mean = idx.mean(1, keepdim=True)\n",
    "    print(decode(X.numpy()[0]), X.shape, idx.shape, mean.shape )\n",
    "    # logits, loss = model(X, Y) # error with input to batch norm         \n",
    "    # optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    # loss.backward()\n",
    "    \n",
    "    # optimizer.step()\n",
    "    # losses.append(loss.item())\n",
    "    break\n",
    "\n",
    "# plt.plot(torch.tensor(losses).log10()), vocab_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
