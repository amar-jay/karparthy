{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f178b8f-f2e1-45cf-837d-dc69c47076f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "torch.__version__\n",
    "\n",
    "g = torch.Generator().manual_seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2ba869a-3d27-4b4f-a104-4a6898a20283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:  ['macie', 'brix', 'gabbanelli', 'rylon', 'yash']\n",
      "number of names:  32033\n",
      "(list of chars, count):  ('.abcdefghijklmnopqrstuvwxyz', 27)\n",
      "(max word length, min word length):  (15, 2)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "with open(\"names.txt\", \"r+\") as f:\n",
    "\twords = f.read().splitlines()\n",
    "\twords = [word.strip() for word in words] # get rid of any trailing spaces\n",
    "\tnames = [w for w in words if w] # get rid of any empty strings\n",
    "\trandom.shuffle(names)\n",
    "\n",
    "min_chars = min(len(v) for v in names)\n",
    "max_chars = max(len(v) for v in names)\n",
    "chars = sorted(list(set(\"\".join(names))))\n",
    "\n",
    "# in replacement of the start and end token. Every name should end with a period. and there should be no start token to begin a sequence\n",
    "chars = ['.'] + chars\n",
    "chars_count = len(chars)\n",
    "print(\"names: \", names[:5])\n",
    "print(\"number of names: \", len(names))\n",
    "print(\"(list of chars, count): \", (\"\".join(chars), chars_count))\n",
    "print(\"(max word length, min word length): \", (max_chars, min_chars))\n",
    "\n",
    "atoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itoa = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "# adding end token to each name\n",
    "names = [list(name) + ['.'] for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24bc12b2-bbff-4ff8-b728-6c756104acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..... => m\n",
      "....m => a\n",
      "...ma => c\n",
      "..mac => i\n",
      ".maci => e\n"
     ]
    }
   ],
   "source": [
    "block_size = 5\n",
    "\n",
    "def build_dset(dset):\n",
    "    X, Y = [], []\n",
    "    for name in dset:\n",
    "        ctx = [0] * block_size\n",
    "        for ch in name:\n",
    "            ix = atoi[ch]\n",
    "            X.append(ctx)\n",
    "            Y.append(ix)\n",
    "            ctx = ctx[1:] + [ix]\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "n1 = int(0.8*len(names))\n",
    "n2 = int(0.9*len(names))\n",
    "\n",
    "X_train, Y_train = build_dset(names[:n1])\n",
    "X_val, Y_val = build_dset(names[n1:n2])\n",
    "X_test, Y_test = build_dset(names[n2:])\n",
    "\n",
    "for c, d in zip(X_train[:len(names[1])], Y_train[:len(names[1])]):\n",
    "    print(''.join(itoa[i.item()] for i in c), \"=>\", itoa[d.item()])\n",
    "    \n",
    "# build_dset(names[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3d507f8-98d5-4c00-89ba-0afda41614ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6954, -1.0087,  0.4551, -1.1384, -1.7112]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Emmbedding:\n",
    "    def __init__(self, num_embedding, embedding_dim):\n",
    "        self.weights = torch.randn((num_embedding, embedding_dim), generator=g)\n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weights[IX]\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [self.weights]\n",
    "        \n",
    "# ------------------------\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True, dtype=None):\n",
    "        self.weights = torch.randn((fan_in, fan_out), generator=g, dtype=dtype) / fan_in**0.5 # note: kaiming init\n",
    "        self.bias = torch.randn((fan_out), generator=g, dtype=dtype) if bias else None\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        self.out = X @ self.weights\n",
    "        if self.bias is not None:\n",
    "            self.out = self.out + self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weights] if self.bias is None else [self.weights, self.bias]\n",
    "\n",
    "# ------------------------\n",
    "\n",
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        self.tanh = torch.tanh\n",
    "    def __call__(self,x):\n",
    "        self.out = self.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "        \n",
    "# ------------------------\n",
    "\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None):\n",
    "        self.beta = torch.zeros((num_features))\n",
    "        self.gamma = torch.ones((num_features))\n",
    "        self.running = track_running_stats\n",
    "        self.mean = None\n",
    "        self.var = None\n",
    "        self.eps = eps\n",
    "        self.momentum = 0.1\n",
    "        self.running_mean = torch.zeros(num_features)\n",
    "        self.running_var = torch.ones(num_features)\n",
    "    def __call__(self, X):\n",
    "        if self.running:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "        else:\n",
    "            mean = torch.mean(X, keepdim=True)\n",
    "            var = torch.var(X, unbiased=False)\n",
    "        \n",
    "        xi = (X - mean) / (var + self.eps) ** 0.5\n",
    "        self.out = self.gamma * xi + self.beta\n",
    "        if not self.running:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = self.running_mean * (1-momentum) + momentum * self.mean\n",
    "                self.running_var = self.running_var * (1-momentum) + momentum * self.var            \n",
    "                \n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.beta, self.gamma]\n",
    "        \n",
    "# ------------------------\n",
    "\n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    def __call__(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        self.out = X\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [param for param in layer.parameters() for layer in self.layers]\n",
    "\n",
    "Sequential([\n",
    "        Linear(5, 30), BatchNorm1d(30), Tanh(),\n",
    "        Linear(30, 30), BatchNorm1d(30), Tanh(),\n",
    "        Linear(30, 30), BatchNorm1d(30), Tanh(),\n",
    "        Linear(30, 30), BatchNorm1d(30), Tanh(),\n",
    "        Linear(30, 5),        \n",
    "    ]\n",
    ")(torch.randn((1,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99140145-ebb1-4bca-9da9-7129c444711c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
